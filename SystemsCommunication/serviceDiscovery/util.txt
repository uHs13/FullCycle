_ docker exec -it consul sh

_ consul agent -dev

_ consul members => Lista os nodes do nosso cluster

Os membros do cluster são do tipo server ou client
É recomendado executar em produção ao menos três servers
Acima disso sempre números impares

Os servers utilizam o raft protocol para definir quem será o lider
As informações replicadas para o lider são replicadas automaticamente
para os outros servidores
Em um client utilizando o consul é possível acessar o comando members também

Consul tem uma API rest e um servidor DNS
Os dois recursos podem ser utilizados para pegar informações

_ curl localhost:8500/v1/catalog/nodes

datacenter é uma separação lógica entre redes consul. Não necessariamente em um
datacenter distante
Para conseguir trabalhar de maneira mais eficiente, o consul utiliza o gossip protocol
para distribuir informações e sincronizar os dados
O gossip protocol tem uma latência menor quando os membros estão na mesma redes

_ apk -U add bind-tools

_ dig @localhost -p 8600

_ dig @localhost -p 8600 consul.node.consul

_ dig @localhost -p 8600 consul.node.consul +short

O consul tem o agente que pode estar no modo client ou server

Construção de cluster com três servers

_ docker exec -it consulserver sh

_ ifconfig

_ mkdir /var/lib/consul

_ mkdir /etc/consul.d

_ consul agent -server -bootstrap-expect=3 -node=consulserver -bind=[ipdoIfconfig] -data-dir=/var/lib/consul -config-dir=/etc/consul.d

_ docker exec -it consulserver sh

_ consul members

Repetir mesmos passos para o server 02

Ao executar o consul members vai ser possível ver que não é exibido o segundo node
Os dois nodes precisam se conhecer, precisamos dar um join entre eles

No terminal do 01 ou 02

_ consul join [ipDoOutroNode]

_ consul members

Deve ser possível visualizar os dois servers na listagem

Repetir os mesmos passos para o 03

Configuração do client

_ ifconfig

_ mkdir /var/lib/consul

_ mkdir /etc/consul.d

_ consul agent -bind=[ipDoNodeClient] -data-dir=/var/lib/consul -config-dir=/etc/consul.d

_ consul members

Verificar que ele está sozinho e é um client

_ consul join [ipDeUmServer]

_ consul members

Verificar que ele está agora no cluster

Registrando um serviço (dentro do container do client)

Uma coisa é registrar um serviço, a outra é você subir o serviço na máquina

Temos que subir um agente na mesma máquina onde o serviço está rodando

_ consul reload

Esse comando faz com que os serviços sejam atualizados

_ apk -U add bind-tools

_ dig @localhost -p 8600 SRV

_ dig @localhost -p 8600 nginx.service.consul

Entrar no container de um dos servers e rodar o mesmo comando para verificar que o resultado é o mesmo
Isso significa que todas as máquinas do cluster estão cientes da existência do serviço

_ curl localhost:8500/v1/catalog/services

Verificar serviços registrados através da API do consul

_ consul catalog nodes -service nginx

Traz os nodes onde o serviço especificado foi registrado

_ consul catalog nodes -detailed

Exibe mais informações dos nodes que estão registados no cluster

_ dig @localhost -p 8600 web.nginx.service.consul

Pesquisa de serviços pelo DNS do cluster através da tag registrada

Criando um outro node com o mesmo serviço registrado

Após criar a nova máquina, precisamos repetir o comando de criação de agente com uma diferença

_ mkdir /var/lib/consul

_ consul agent -bind=[ipDoNodeClient] -data-dir=/var/lib/consul -config-dir=/etc/consul.d -retry-join=[ipDeUmNodeServer] -retry-join=[ipDeOutroNodeServer]

Com a flag -retry-join podemos definir em quais servers o novo client vai tentar se ligar. Caso não consiga se comunicar com o primeiro, ele tenta no segundo

_ consul members

Verificar que temos o segundo client rodando

_ apk -U add bind-tools

_ dig @localhost -p 8600 nginx.service.consul

Verificar via DNS que temos dois nodes executando o serviço do nginx

Sempre temos um agente consul e o serviço sendo executado no node client

Caso a gente precise consultar algum outro serviço, não é necessário consultar o server do consul

É possível consultar o próprio client do consul, porque todos os serviços ficam sincronizados entre os servers e agents

Os clients tem todas as informações que os servers tem, com exceção da parte de membership, que é o processo onde os servers definem quem vai ser o líder

Health check ou checks verificam se o serviço instalado no node está saudável. O consul não vai mostrar o ip de um serviço que está fora

Adicionar o check dentro do json de um dos serviços

_ dig @localhost -p 8600 nginx.service.consul

Verificar que temos dois nodes com o serviço do nginx registrado

_ consul reload

Verificar que o serviço com check sumiu da listagem do dig
O check verificou que o serviço não está saudável no node e removeu ele da listagem

Acessar o terminal do container que tem o check

_ app add nginx

_ ps

Verificar que o nginx ainda não está sendo executado

_ nginx

_ ps

Inicializar o nginx no node e verificar que está sendo executado

_ curl localhost

Verificar que a porta 80 tem um retorno, porém não é o ideal, pois é um 404

_ apk add vim

_ mkdir /usr/share/nginx/html -p

_ vim /etc/nginx/http.d/default.conf

Substituir isso:

#Everything is a 404
location / {
    return 404
}

Por isso:

root /usr/share/nginx/html;

_ vim /usr/share/nginx/html/index.html

Digitar alguma coisa no html

_ nginx -s reload

Esse comando faz o reload do nginx

_ dig @localhost -p 8600 nxing.service.consulserver

